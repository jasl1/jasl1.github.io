---
permalink: /
title: "About me"
author_profile: true
---

- Research Scientist at INformation Security and Privacy: Interdisciplinary Research and Education [(INSPIRE)](https://inspire.gsu.edu/) center
- Ph.D. candidate in Computer Science at [Georgia State University](https://www.gsu.edu/), Department of [Computer Science](https://csds.gsu.edu/)
- Advised by Prof. [Daniel Takabi](https://www.odu.edu/article/odu-names-daniel-takabi-as-director-for-school-of-cybersecurity), and Prof. [Zhipeng Cai](https://cai.csgsu.org/)


Research Interest: Natural Language Processing (NLP), Large Language Models (LLMs), and Trustworthy Artificial Intelligence <br/><br/>
I am a last-year PhD candidate specializing in Natural Language Processing (NLP), Trustworthy Artificial Intelligence (AI), and Machine Learning (ML/LLMs), with a strong background in various programming languages. Highly motivated, I have contributed to several research projects and publications over the years, showcasing my expertise and dedication to the field. With 8 years of expertise in NLP models and tasks, over 4 years of experience in secure AI, and robust PLMs & LLMs, I am a Robust Machine Learning Researcher proficient in programming languages and algorithm design, with over 10 years of experience. I am currently conducting research aimed at enhancing the robustness and efficiency of Pre-trained Language Models (PLMs) for adversarial NLP applications, and I am scheduled to defend my PhD dissertation in the next few weeks. Actively seeking full-time or part-time positions as an NLP/Generative AI Scientist or Machine Learning Researcher, I am eager to contribute to the further development of robust and efficient PLMs/LLMs for real-world applications. 
 <br/>
  <br/>
As part of my previous practical work, I have undertaken a variety of projects that showcase my expertise in natural language processing and machine learning, specifically in large language models. I participated in an industrial project aimed at detecting various types of plagiarism (e.g., paraphrases and semantic plagiarism) within a corpus of 2.5 million papers. Furthermore, I played an integral role in developing a sophisticated text alignment framework, where I explored fundamental data mining techniques to precisely detect text reuse segments. I fine-tuned a pre-trained language model (T5) for text summarization using the Prefix-Tuning technique on the CNN/Daily Mail dataset. Additionally, I built Retrieval-Augmented Generation (RAG) systems using LlamaIndex, which involved loading data from various sources, creating vector indexes, querying the indexes, and evaluating the system's performance. I also explored different prompt engineering techniques, such as Few-shot, Zero-shot, and Chain-of-Thought, to build a useful LLM application. In the realm of sentiment analysis, I created a multi-modal sentiment analysis model for movie reviews using RNN/LSTM, deployed it on AWS, managed the codebase with Git, and utilized multi-modal analysis. Furthermore, I extended a conversational AI assistant to handle customer inquiries and provide support for a hypothetical e-commerce company. Lastly, I developed an intelligent document processing system using Azure AI and Machine Learning services to extract relevant information from scanned documents, classify them based on their content, and provide insightful analysis.<br/> 


News
======
- **[May 2024]** Our paper titled [RobustSentEmbed: Robust Sentence Embeddings Using Adversarial Self-Supervised Contrastive Learning](https://openreview.net/pdf?id=Kluyc7Jz1fXH) has been accepted by [North American Chapter of the Association for Computational Linguistics](https://2024.naacl.org/) (NAACL 2024). The preprint version is accessible via [this link](https://arxiv.org/abs/2403.11082).
- **[February 2024]** Our paper titled [A Semantic, Syntactic, And Context-Aware Natural Language Adversarial Example Generator](https://ieeexplore.ieee.org/abstract/document/10416371) is published on the [IEEE Transactions on Dependable and Secure Computing](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8858).
- **[December 2023]** Our paper on robust text representation is accepted by [Empirical Methods in Natural Language Processing](https://2023.emnlp.org/) (EMNLP 2023). The preprint version is accessible via [this link](https://aclanthology.org/2023.findings-emnlp.305/).
- **[October 2023]** The source code for our robust text representation is available in the [RobustEmbed repository](https://github.com/jasl1/RobustEmbed).
